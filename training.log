2024-12-28 21:18:43,444 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 21:18:43,444 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 21:18:43,444 [INFO] Loading dataset...
2024-12-28 21:18:43,625 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 21:18:46,831 [INFO] Model loaded on: cuda:0
2024-12-28 21:18:46,831 [INFO] Processing datasets...
2024-12-28 21:18:47,738 [INFO] Starting training...
2024-12-28 21:18:48,049 [ERROR] Training failed: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 136, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/accelerate/utils/operations.py", line 823, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/accelerate/utils/operations.py", line 811, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 736, in forward
    hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 21:18:48,053 [ERROR] GPU Memory: 1.50GB
2024-12-28 21:52:54,721 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 21:52:54,722 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 21:52:54,722 [INFO] Loading dataset...
2024-12-28 21:52:54,939 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 21:52:58,255 [INFO] Model loaded on: cuda:0
2024-12-28 21:52:58,255 [INFO] Processing datasets...
2024-12-28 21:52:59,328 [INFO] Starting training...
2024-12-28 21:52:59,727 [ERROR] Training failed: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 136, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 736, in forward
    hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 21:52:59,732 [ERROR] GPU Memory: 1.50GB
2024-12-28 21:53:51,924 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 21:53:51,924 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 21:53:51,925 [INFO] Loading dataset...
2024-12-28 21:53:52,120 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 21:53:55,522 [INFO] Model loaded on: cuda:0
2024-12-28 21:53:55,523 [INFO] Processing datasets...
2024-12-28 21:53:56,661 [INFO] Starting training...
2024-12-28 21:53:57,022 [ERROR] Training failed: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 136, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 736, in forward
    hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 21:53:57,025 [ERROR] GPU Memory: 1.50GB
2024-12-28 21:54:55,019 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 21:54:55,020 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 21:54:55,020 [INFO] Loading dataset...
2024-12-28 21:54:55,217 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 21:54:58,587 [INFO] Model loaded on: cuda:0
2024-12-28 21:54:58,587 [INFO] Processing datasets...
2024-12-28 21:54:59,785 [INFO] Starting training...
2024-12-28 21:55:00,148 [ERROR] Training failed: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 136, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 736, in forward
    hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 21:55:00,152 [ERROR] GPU Memory: 1.50GB
2024-12-28 21:59:59,712 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 21:59:59,713 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 21:59:59,713 [INFO] Loading dataset...
2024-12-28 21:59:59,936 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:00:42,354 [INFO] Model loaded on: cuda:0
2024-12-28 22:00:42,354 [INFO] Processing datasets...
2024-12-28 22:00:43,335 [INFO] Starting training...
2024-12-28 22:00:43,659 [ERROR] Training failed: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 136, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 736, in forward
    hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 22:00:43,663 [ERROR] GPU Memory: 1.50GB
2024-12-28 22:15:16,195 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 22:15:16,195 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 22:15:16,195 [INFO] Loading dataset...
2024-12-28 22:15:16,399 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:15:18,922 [INFO] Model loaded on: cpu
2024-12-28 22:15:18,922 [INFO] Processing datasets...
2024-12-28 22:15:18,942 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,942 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,942 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,950 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,951 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,951 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,955 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,955 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,955 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,958 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,958 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,958 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,960 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,961 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,961 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,968 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,968 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,968 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,979 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,980 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,980 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,987 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,987 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,987 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,993 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,993 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,993 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:18,996 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:18,996 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:18,996 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,005 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,006 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,006 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,012 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,012 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,012 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,015 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,015 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,015 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,020 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,021 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,021 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,024 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,024 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,024 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,029 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,029 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,029 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,036 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,037 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,037 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,042 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,042 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,042 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,047 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,047 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,047 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,052 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,052 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,052 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,058 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,058 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,058 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,066 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,067 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,067 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,073 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,074 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,074 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,081 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,082 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,082 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,085 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,085 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,085 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,091 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,091 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,091 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,097 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,097 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,097 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,102 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,102 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,102 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,107 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,108 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,108 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,114 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,114 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,115 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,119 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,119 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,119 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,124 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,125 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,125 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,133 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,133 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,133 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,137 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,137 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,137 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,139 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,139 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,140 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,144 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,144 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,144 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,151 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,151 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,151 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,160 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,160 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,160 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,165 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,165 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,165 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,167 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,167 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,167 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,169 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,170 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,170 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,174 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,174 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,174 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,178 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,178 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,178 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,187 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,187 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,187 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,194 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,194 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,194 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,208 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,208 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,208 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,216 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,216 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,216 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,221 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,222 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,222 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,227 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,227 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,227 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:19,231 [INFO] Input IDs shape: torch.Size([2, 128])
2024-12-28 22:15:19,231 [INFO] Attention mask shape: torch.Size([2, 128])
2024-12-28 22:15:19,231 [INFO] Labels shape: torch.Size([2, 128])
2024-12-28 22:15:20,395 [INFO] Starting training...
2024-12-28 22:20:20,025 [INFO] Training completed and model saved!
2024-12-28 22:31:11,472 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 22:31:11,472 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 22:31:11,473 [INFO] Loading dataset...
2024-12-28 22:31:11,679 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:31:14,855 [INFO] Model loaded on: cuda:0
2024-12-28 22:31:14,855 [INFO] Processing datasets...
2024-12-28 22:31:15,018 [INFO] Starting training...
2024-12-28 22:34:49,423 [INFO] Training completed and model saved!
2024-12-28 22:35:24,294 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 22:35:24,295 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 22:35:24,295 [INFO] Loading dataset...
2024-12-28 22:35:24,501 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:35:28,018 [INFO] Model loaded on: cuda:0
2024-12-28 22:35:28,018 [INFO] Processing datasets...
2024-12-28 22:35:28,210 [INFO] Starting training...
2024-12-28 22:39:00,484 [INFO] Training completed and model saved!
2024-12-28 22:39:32,371 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 22:39:32,372 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 22:39:32,372 [INFO] Loading dataset...
2024-12-28 22:39:32,585 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:39:35,293 [INFO] Model loaded on: cuda:0
2024-12-28 22:39:35,293 [INFO] Processing datasets...
2024-12-28 22:39:35,541 [ERROR] Training failed: 'function' object has no attribute 'on_init_end'
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 186, in train
    trainer = Seq2SeqTrainer(
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 72, in __init__
    super().__init__(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 771, in __init__
    self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 465, in on_init_end
    return self.call_event("on_init_end", args, state, control)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 519, in call_event
    result = getattr(callback, event)(
             ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'on_init_end'
2024-12-28 22:39:35,543 [ERROR] GPU Memory: 1.49GB
2024-12-28 22:39:35,729 [ERROR] Script failed: 'function' object has no attribute 'on_init_end'
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 225, in <module>
    train()
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 186, in train
    trainer = Seq2SeqTrainer(
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 72, in __init__
    super().__init__(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 771, in __init__
    self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 465, in on_init_end
    return self.call_event("on_init_end", args, state, control)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 519, in call_event
    result = getattr(callback, event)(
             ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'on_init_end'
2024-12-28 22:46:10,543 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 22:46:10,543 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 22:46:10,543 [INFO] Loading dataset...
2024-12-28 22:46:10,712 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:46:12,760 [INFO] Model loaded on: cuda:0
2024-12-28 22:46:12,761 [INFO] Processing datasets...
2024-12-28 22:46:12,932 [INFO] Model device: cuda:0
2024-12-28 22:46:12,932 [INFO] CUDA active: True
2024-12-28 22:46:12,932 [INFO] Current device: 0
2024-12-28 22:46:12,932 [INFO] Starting training...
2024-12-28 22:46:15,169 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 22:46:16,360 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 22:46:21,482 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:46:25,114 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:46:31,458 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:46:37,655 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:46:41,043 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:46:44,469 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:46:50,633 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:46:56,868 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:03,032 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:06,227 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:06,228 [INFO] GPU Memory at epoch end: 4276.82MB
2024-12-28 22:47:12,223 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:18,345 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:24,382 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:30,488 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:36,558 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:42,765 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:48,858 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:47:54,900 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:00,993 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:07,064 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:13,155 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:16,306 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:16,307 [INFO] GPU Memory at epoch end: 4276.82MB
2024-12-28 22:48:22,473 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:28,638 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:34,844 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:41,033 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:47,572 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:48:53,932 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:49:00,210 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:49:06,434 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:49:12,585 [INFO] GPU Memory Usage: 4276.82MB
2024-12-28 22:49:18,044 [INFO] GPU Memory at epoch end: 4276.82MB
2024-12-28 22:49:20,416 [INFO] Training completed and model saved!
2024-12-28 22:51:12,934 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 22:51:12,934 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 22:51:12,934 [INFO] Loading dataset...
2024-12-28 22:51:13,136 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:51:15,298 [INFO] Model loaded on: cuda:0
2024-12-28 22:51:15,298 [INFO] Processing datasets...
2024-12-28 22:51:15,487 [INFO] Model device: cuda:0
2024-12-28 22:51:15,487 [INFO] CUDA active: True
2024-12-28 22:51:15,487 [INFO] Current device: 0
2024-12-28 22:51:15,691 [INFO] Starting training...
2024-12-28 22:51:22,415 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:22,415 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:29,075 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:29,076 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:38,370 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:38,371 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:45,244 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:45,244 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:51,238 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:51,239 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:56,925 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:51:56,926 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:02,944 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:02,944 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:09,149 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:09,150 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:15,281 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:15,281 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:21,521 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:21,521 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:27,737 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:27,737 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:31,670 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:52:31,671 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:52:31,672 [INFO] GPU Memory at epoch end: 4277.81MB
2024-12-28 22:52:38,014 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:38,014 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:44,264 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:44,265 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:50,561 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:50,561 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:56,807 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:52:56,808 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:02,948 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:02,949 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:09,347 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:09,347 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:15,765 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:15,766 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:21,140 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:21,141 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:25,307 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:25,307 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:29,483 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:29,483 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:34,162 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:34,162 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:37,548 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:53:37,548 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:53:37,550 [INFO] GPU Memory at epoch end: 4277.81MB
2024-12-28 22:53:41,751 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:41,751 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:45,916 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:45,916 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:50,182 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:50,182 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:54,432 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:54,433 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:58,736 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:53:58,736 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:03,066 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:03,066 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:07,940 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:07,941 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:12,314 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:12,314 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:16,800 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:16,800 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:24,922 [INFO] GPU Memory at epoch end: 4277.82MB
2024-12-28 22:54:28,843 [INFO] Training completed and model saved!
2024-12-28 22:54:47,401 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 22:54:47,401 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 22:54:47,402 [INFO] Loading dataset...
2024-12-28 22:54:47,597 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 22:54:50,148 [INFO] Model loaded on: cuda:0
2024-12-28 22:54:50,149 [INFO] Processing datasets...
2024-12-28 22:54:50,351 [INFO] Model device: cuda:0
2024-12-28 22:54:50,351 [INFO] CUDA active: True
2024-12-28 22:54:50,351 [INFO] Current device: 0
2024-12-28 22:54:50,576 [INFO] Starting training...
2024-12-28 22:54:55,962 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:54:55,962 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:01,477 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:01,478 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:07,122 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:07,122 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:12,899 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:12,899 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:18,383 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:18,384 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:23,949 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:23,949 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:30,030 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:30,031 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:36,260 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:36,260 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:42,361 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:42,361 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:48,539 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:48,539 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:54,685 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:54,685 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:55:58,379 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:55:58,379 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:55:58,381 [INFO] GPU Memory at epoch end: 4277.81MB
2024-12-28 22:56:04,645 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:04,645 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:10,843 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:10,844 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:17,168 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:17,169 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:23,773 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:23,773 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:30,165 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:30,165 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:36,667 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:36,668 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:43,056 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:43,057 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:49,407 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:49,408 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:54,907 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:54,907 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:59,159 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:56:59,159 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:03,392 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:03,392 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:06,705 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:57:06,705 [INFO] GPU Memory Usage: 4277.81MB
2024-12-28 22:57:06,706 [INFO] GPU Memory at epoch end: 4277.81MB
2024-12-28 22:57:10,884 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:10,885 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:15,119 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:15,119 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:19,437 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:19,438 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:23,712 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:23,712 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:28,050 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:28,051 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:32,396 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:32,397 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:36,824 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:36,825 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:42,033 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:42,034 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:47,001 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:47,002 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 22:57:54,297 [INFO] GPU Memory at epoch end: 4277.82MB
2024-12-28 22:58:01,900 [INFO] Training completed and model saved!
2024-12-28 23:22:30,684 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:22:30,685 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:22:30,685 [INFO] Loading dataset...
2024-12-28 23:22:30,875 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:22:32,831 [INFO] Model loaded on: cuda:0
2024-12-28 23:22:32,831 [INFO] Processing datasets...
2024-12-28 23:22:33,000 [INFO] Model device: cuda:0
2024-12-28 23:22:33,000 [INFO] CUDA active: True
2024-12-28 23:22:33,001 [INFO] Current device: 0
2024-12-28 23:22:33,157 [INFO] Starting training...
2024-12-28 23:22:38,380 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:22:38,380 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:22:44,009 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:22:44,009 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:22:49,609 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:22:49,610 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:30:59,813 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:30:59,813 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:30:59,813 [INFO] Loading dataset...
2024-12-28 23:31:00,115 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:31:02,149 [INFO] Model loaded on: cuda:0
2024-12-28 23:31:02,149 [INFO] Processing datasets...
2024-12-28 23:31:22,242 [INFO] Model device: cuda:0
2024-12-28 23:31:22,243 [INFO] CUDA active: True
2024-12-28 23:31:22,243 [INFO] Current device: 0
2024-12-28 23:31:22,368 [INFO] Starting training...
2024-12-28 23:31:22,696 [ERROR] Training failed: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 247, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 733, in forward
    embed_pos = self.embed_positions(input_shape)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 87, in forward
    return super().forward(positions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 23:31:22,699 [ERROR] GPU Memory: 1.50GB
2024-12-28 23:31:22,700 [ERROR] Script failed: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 247, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 733, in forward
    embed_pos = self.embed_positions(input_shape)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 87, in forward
    return super().forward(positions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 265, in <module>
    train()
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 260, in train
    torch.cuda.empty_cache()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 23:31:58,565 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:31:58,565 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:31:58,565 [INFO] Loading dataset...
2024-12-28 23:31:58,844 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:32:00,893 [INFO] Model loaded on: cuda:0
2024-12-28 23:32:00,893 [INFO] Processing datasets...
2024-12-28 23:32:21,494 [INFO] Model device: cuda:0
2024-12-28 23:32:21,494 [INFO] CUDA active: True
2024-12-28 23:32:21,494 [INFO] Current device: 0
2024-12-28 23:32:21,628 [INFO] Starting training...
2024-12-28 23:32:21,892 [ERROR] Training failed: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 247, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 733, in forward
    embed_pos = self.embed_positions(input_shape)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 87, in forward
    return super().forward(positions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 23:32:21,896 [ERROR] GPU Memory: 1.50GB
2024-12-28 23:32:21,896 [ERROR] Script failed: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 247, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2524, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3654, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3708, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1296, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 1149, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 733, in forward
    embed_pos = self.embed_positions(input_shape)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/models/blenderbot/modeling_blenderbot.py", line 87, in forward
    return super().forward(positions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 265, in <module>
    train()
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 260, in train
    torch.cuda.empty_cache()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 23:33:13,353 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:33:13,353 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:33:13,353 [INFO] Loading dataset...
2024-12-28 23:33:13,524 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:33:15,848 [INFO] Model loaded on: cuda:0
2024-12-28 23:33:15,849 [INFO] Processing datasets...
2024-12-28 23:33:16,025 [ERROR] Training failed: 'function' object has no attribute 'on_init_end'
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 186, in train
    trainer = Seq2SeqTrainer(
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 72, in __init__
    super().__init__(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 771, in __init__
    self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 465, in on_init_end
    return self.call_event("on_init_end", args, state, control)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 519, in call_event
    result = getattr(callback, event)(
             ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'on_init_end'
2024-12-28 23:33:16,028 [ERROR] GPU Memory: 1.49GB
2024-12-28 23:33:16,198 [ERROR] Script failed: 'function' object has no attribute 'on_init_end'
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 225, in <module>
    train()
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 186, in train
    trainer = Seq2SeqTrainer(
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 72, in __init__
    super().__init__(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 771, in __init__
    self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 465, in on_init_end
    return self.call_event("on_init_end", args, state, control)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 519, in call_event
    result = getattr(callback, event)(
             ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'on_init_end'
2024-12-28 23:33:33,110 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:33:33,110 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:33:33,111 [INFO] Loading dataset...
2024-12-28 23:33:33,292 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:33:35,288 [INFO] Model loaded on: cuda:0
2024-12-28 23:33:35,289 [INFO] Processing datasets...
2024-12-28 23:33:35,471 [ERROR] Training failed: 'function' object has no attribute 'on_init_end'
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 186, in train
    trainer = Seq2SeqTrainer(
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 72, in __init__
    super().__init__(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 771, in __init__
    self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 465, in on_init_end
    return self.call_event("on_init_end", args, state, control)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 519, in call_event
    result = getattr(callback, event)(
             ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'on_init_end'
2024-12-28 23:33:35,473 [ERROR] GPU Memory: 1.49GB
2024-12-28 23:33:35,658 [ERROR] Script failed: 'function' object has no attribute 'on_init_end'
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 225, in <module>
    train()
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 186, in train
    trainer = Seq2SeqTrainer(
              ^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 72, in __init__
    super().__init__(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 771, in __init__
    self.control = self.callback_handler.on_init_end(self.args, self.state, self.control)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 465, in on_init_end
    return self.call_event("on_init_end", args, state, control)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_callback.py", line 519, in call_event
    result = getattr(callback, event)(
             ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'on_init_end'
2024-12-28 23:33:57,880 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:33:57,881 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:33:57,881 [INFO] Loading dataset...
2024-12-28 23:33:58,053 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:33:59,944 [INFO] Model loaded on: cuda:0
2024-12-28 23:33:59,944 [INFO] Processing datasets...
2024-12-28 23:34:00,127 [INFO] Model device: cuda:0
2024-12-28 23:34:00,128 [INFO] CUDA active: True
2024-12-28 23:34:00,128 [INFO] Current device: 0
2024-12-28 23:34:00,316 [INFO] Starting training...
2024-12-28 23:34:02,065 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:34:02,066 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:34:03,520 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:34:03,521 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:34:08,515 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:08,515 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:12,235 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:12,235 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:18,824 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:18,824 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:25,427 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:25,427 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:29,455 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:29,455 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:33,543 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:33,543 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:40,636 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:40,637 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:47,674 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:47,674 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:54,823 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:54,823 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:58,643 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:58,643 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:34:58,645 [INFO] GPU Memory at epoch end: 4277.82MB
2024-12-28 23:35:05,644 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:05,645 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:12,901 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:12,902 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:19,906 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:19,906 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:27,043 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:27,043 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:34,146 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:34,146 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:41,224 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:41,224 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:35:57,560 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:35:57,560 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:35:57,560 [INFO] Loading dataset...
2024-12-28 23:35:57,749 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:36:00,082 [INFO] Model loaded on: cuda:0
2024-12-28 23:36:00,082 [INFO] Processing datasets...
2024-12-28 23:36:00,250 [INFO] Model device: cuda:0
2024-12-28 23:36:00,251 [INFO] CUDA active: True
2024-12-28 23:36:00,251 [INFO] Current device: 0
2024-12-28 23:36:00,444 [INFO] Starting training...
2024-12-28 23:36:02,412 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:36:02,413 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:36:03,994 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:36:03,995 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:36:08,837 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:08,838 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:12,601 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:12,601 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:19,204 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:19,205 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:25,911 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:25,911 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:30,290 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:30,290 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:34,517 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:36:34,518 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:28,814 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:37:28,814 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:37:28,814 [INFO] Loading dataset...
2024-12-28 23:37:28,993 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:37:30,967 [INFO] Model loaded on: cuda:0
2024-12-28 23:37:30,967 [INFO] Processing datasets...
2024-12-28 23:37:31,128 [INFO] Model device: cuda:0
2024-12-28 23:37:31,128 [INFO] CUDA active: True
2024-12-28 23:37:31,128 [INFO] Current device: 0
2024-12-28 23:37:31,292 [INFO] Starting training...
2024-12-28 23:37:33,022 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:37:33,022 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:37:34,485 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:37:34,486 [INFO] GPU Memory Usage: 1436.80MB
2024-12-28 23:37:39,300 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:39,300 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:42,870 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:42,870 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:49,201 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:49,201 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:55,651 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:55,652 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:59,714 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:37:59,714 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:03,906 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:03,906 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:10,678 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:10,679 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:17,669 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:17,669 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:24,457 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:24,458 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:28,220 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:28,220 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:28,221 [INFO] GPU Memory at epoch end: 4277.82MB
2024-12-28 23:38:34,997 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:34,997 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:42,047 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:42,048 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:48,980 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:48,981 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:56,056 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:38:56,057 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:03,224 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:03,225 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:10,444 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:10,444 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:17,295 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:17,295 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:24,715 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:24,716 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:31,780 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:31,781 [INFO] GPU Memory Usage: 4277.82MB
2024-12-28 23:39:35,551 [ERROR] Training failed: CUDA error: out of memory
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 247, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2577, in _inner_training_loop
    self.optimizer.step()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/accelerate/optimizer.py", line 165, in step
    self.scaler.step(self.optimizer, closure)
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 457, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 352, in _maybe_opt_step
    retval = optimizer.step(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/accelerate/optimizer.py", line 210, in patched_step
    return method(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/adamw.py", line 220, in step
    adamw(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/adamw.py", line 782, in adamw
    func(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/adamw.py", line 606, in _multi_tensor_adamw
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 23:39:35,557 [ERROR] GPU Memory: 5.98GB
2024-12-28 23:39:35,557 [ERROR] Script failed: CUDA error: out of memory
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 247, in train
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2577, in _inner_training_loop
    self.optimizer.step()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/accelerate/optimizer.py", line 165, in step
    self.scaler.step(self.optimizer, closure)
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 457, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 352, in _maybe_opt_step
    retval = optimizer.step(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/accelerate/optimizer.py", line 210, in patched_step
    return method(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 137, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/adamw.py", line 220, in step
    adamw(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 154, in maybe_fallback
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/adamw.py", line 782, in adamw
    func(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/optim/adamw.py", line 606, in _multi_tensor_adamw
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 265, in <module>
    train()
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_gpu.py", line 260, in train
    torch.cuda.empty_cache()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: out of memory
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

2024-12-28 23:43:47,617 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:43:47,617 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:43:47,617 [INFO] Loading dataset...
2024-12-28 23:43:47,809 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:43:49,935 [INFO] Model loaded on: cuda:0
2024-12-28 23:43:49,936 [INFO] Processing datasets...
2024-12-28 23:43:50,098 [INFO] Model device: cuda:0
2024-12-28 23:43:50,098 [INFO] CUDA active: True
2024-12-28 23:43:50,098 [INFO] Current device: 0
2024-12-28 23:43:50,289 [INFO] Starting training...
2024-12-28 23:43:52,831 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:43:52,831 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:43:55,156 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:43:55,156 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:43:57,469 [INFO] GPU Memory Usage: 1436.83MB
2024-12-28 23:43:57,469 [INFO] GPU Memory Usage: 1436.83MB
2024-12-28 23:43:57,469 [INFO] GPU Memory at epoch end: 1436.80MB
2024-12-28 23:43:59,812 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:43:59,813 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:44:05,462 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:44:05,462 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:44:16,076 [INFO] GPU Memory Usage: 4277.85MB
2024-12-28 23:44:16,077 [INFO] GPU Memory Usage: 4277.85MB
2024-12-28 23:44:16,077 [INFO] GPU Memory at epoch end: 4277.82MB
2024-12-28 23:44:28,271 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:44:28,271 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:44:40,083 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:44:40,083 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:44:51,007 [INFO] GPU Memory Usage: 4277.85MB
2024-12-28 23:44:51,007 [INFO] GPU Memory Usage: 4277.85MB
2024-12-28 23:44:59,463 [INFO] GPU Memory at epoch end: 4277.85MB
2024-12-28 23:45:02,818 [INFO] Training completed and model saved!
2024-12-28 23:45:51,809 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:45:51,810 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:45:51,810 [INFO] Loading dataset...
2024-12-28 23:45:52,078 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:45:54,532 [INFO] Model loaded on: cuda:0
2024-12-28 23:45:54,533 [INFO] Processing datasets...
2024-12-28 23:46:13,211 [INFO] Model device: cuda:0
2024-12-28 23:46:13,211 [INFO] CUDA active: True
2024-12-28 23:46:13,211 [INFO] Current device: 0
2024-12-28 23:46:13,345 [INFO] Starting training...
2024-12-28 23:46:16,349 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:46:16,349 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:46:18,495 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:46:18,495 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:46:24,483 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:46:24,483 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:46:33,658 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:46:33,659 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:46:45,354 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:46:45,354 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:46:52,864 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:46:52,864 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:04,773 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:04,774 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:15,139 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:15,140 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:25,492 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:25,492 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:37,298 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:37,299 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:49,377 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:47:49,378 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:00,156 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:00,157 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:12,465 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:12,465 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:22,953 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:22,954 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:29,761 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:29,762 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:36,412 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:36,412 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:43,297 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:43,298 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:51,047 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:51,047 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:58,981 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:48:58,982 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:07,035 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:07,035 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:15,139 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:15,140 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:23,272 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:23,273 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:31,725 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:31,725 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:40,176 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:40,176 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:47,783 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:47,784 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:56,601 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:49:56,601 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:05,650 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:05,650 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:16,435 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:16,435 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:26,605 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:26,605 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:34,892 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:34,892 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:42,827 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:42,827 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:50,773 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:50,774 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:57,852 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:50:57,852 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:51:05,087 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:51:05,087 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:51:13,597 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:51:13,597 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:56:24,711 [INFO] Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2024-12-28 23:56:24,711 [INFO] Total GPU Memory: 4.00 GB
2024-12-28 23:56:24,711 [INFO] Loading dataset...
2024-12-28 23:56:24,980 [INFO] Loading facebook/blenderbot-400M-distill...
2024-12-28 23:56:27,164 [INFO] Model loaded on: cuda:0
2024-12-28 23:56:27,165 [INFO] Processing datasets...
2024-12-28 23:56:47,145 [INFO] Model device: cuda:0
2024-12-28 23:56:47,145 [INFO] CUDA active: True
2024-12-28 23:56:47,145 [INFO] Current device: 0
2024-12-28 23:56:47,293 [INFO] Starting training...
2024-12-28 23:56:50,120 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:56:50,120 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:56:52,211 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:56:52,211 [INFO] GPU Memory Usage: 1436.84MB
2024-12-28 23:56:57,612 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:56:57,612 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:06,363 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:06,364 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:18,253 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:18,253 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:25,991 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:25,991 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:37,643 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:37,643 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:47,914 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:47,915 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:58,523 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:57:58,523 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:10,371 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:10,372 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:22,794 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:22,795 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:33,439 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:33,440 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:45,478 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:45,478 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:55,658 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:58:55,659 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:02,082 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:02,082 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:08,401 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:08,401 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:14,932 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:14,932 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:21,594 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:21,594 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:29,697 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:29,698 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:37,379 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:37,380 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:45,511 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:45,511 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:53,646 [INFO] GPU Memory Usage: 4277.86MB
2024-12-28 23:59:53,646 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:02,046 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:02,047 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:10,736 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:10,736 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:19,835 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:19,835 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:27,798 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:27,798 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:37,596 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:37,596 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:47,279 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:47,280 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:56,947 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:00:56,947 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:03,821 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:03,821 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:10,090 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:10,091 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:16,458 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:16,458 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:23,499 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:23,499 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:30,525 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:30,526 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:37,346 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:37,346 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:45,286 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:45,286 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:52,336 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:01:52,336 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:00,427 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:00,428 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:08,697 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:08,697 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:16,777 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:16,777 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:25,323 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:25,324 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:34,117 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:34,118 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:43,875 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:43,876 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:53,430 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:02:53,430 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:02,484 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:02,485 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:09,098 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:09,098 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:16,832 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:16,832 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:23,853 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:23,853 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:31,780 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:31,780 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:41,721 [INFO] GPU Memory Usage: 4277.86MB
2024-12-29 00:03:41,722 [INFO] GPU Memory Usage: 4277.86MB
