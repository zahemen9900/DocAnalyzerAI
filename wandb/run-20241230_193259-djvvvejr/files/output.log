 45%|██████████████████████████████████████████████████████████████▋                                                                           | 50/110 [56:09<1:06:57, 66.95s/it]Traceback (most recent call last):
{'loss': 45.4187, 'grad_norm': 153.54859924316406, 'learning_rate': 4.545454545454546e-05, 'epoch': 0.44}
{'loss': 45.0135, 'grad_norm': 150.38308715820312, 'learning_rate': 4.898732434036244e-05, 'epoch': 0.89}
{'loss': 42.4811, 'grad_norm': 147.22555541992188, 'learning_rate': 4.559191453574582e-05, 'epoch': 1.31}
{'loss': 45.2957, 'grad_norm': 148.36343383789062, 'learning_rate': 4.014024217844167e-05, 'epoch': 1.76}
{'loss': 42.9015, 'grad_norm': 142.92152404785156, 'learning_rate': 3.3176699082935545e-05, 'epoch': 2.18}
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_quantized.py", line 329, in <module>
    train_quantized()
  File "/home/zahemen/projects/dl-lib/DocAnalyzerAI/src/train_finbot_quantized.py", line 299, in train_quantized
    trainer.train()
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2164, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 2591, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3049, in _maybe_log_save_evaluate
    metrics = self._evaluate(trial, ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 3003, in _evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 195, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 4050, in evaluate
    output = eval_loop(
             ^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer.py", line 4244, in evaluation_loop
    losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/trainer_seq2seq.py", line 331, in prediction_step
    generated_tokens = self.model.generate(**generation_inputs, **gen_kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2283, in generate
    result = self._beam_search(
             ^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 3524, in _beam_search
    next_token_scores_processed = logits_processor(input_ids, next_token_scores)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 104, in __call__
    scores = processor(input_ids, scores)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 974, in __call__
    banned_batch_tokens = _calc_banned_ngram_tokens(self.ngram_size, input_ids, num_batch_hypotheses, cur_len)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 914, in _calc_banned_ngram_tokens
    generated_ngrams = _get_ngrams(ngram_size, prev_input_ids, num_hypos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zahemen/miniconda3/envs/transformer_env/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 875, in _get_ngrams
    gen_tokens = prev_input_ids[idx].tolist()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
