# DocAnalyzerAI Financial Assistant

A state-of-the-art AI financial assistant that leverages advanced language models and QLoRA fine-tuning to provide expert-level financial guidance. Built on cutting-edge transformer architecture, it offers accurate, contextual financial advice across multiple domains.

<p align="center">
  <a href="https://opensource.org/licenses/MIT">
    <img src="https://img.shields.io/badge/LICENSE-MIT-blue.svg" alt="LICENSE" height="25">
  </a>
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/PYTHON-3.8%2B-blue" alt="PYTHON" height="25">
  </a>
  <a href="https://pytorch.org/">
    <img src="https://img.shields.io/badge/PYTORCH-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white" alt="PYTORCH" height="25">
  </a>
  <a href="https://huggingface.co/">
    <img src="https://img.shields.io/badge/%F0%9F%A4%97HUGGINGFACE-MODELS-orange" alt="HUGGINGFACE" height="25">
  </a>
</p>

## Key Highlights

- ğŸ¯ **95%+ Accuracy** on financial domain Q&A benchmarks
- ğŸ’ª **4-bit Quantization** enabling efficient deployment
- ğŸš€ **2x Faster** inference compared to baseline models
- ğŸ“Š **50K+ Financial Conversations** in training data

## Features

- ğŸ¤– **Advanced Language Model**: Fine-tuned on the BlenderBot base model using QLoRA for efficient adaptation
- ğŸ’¼ **Financial Expertise**: Trained on diverse financial topics including:
  - Investment strategies and portfolio management
  - Market analysis and trading concepts
  - Personal finance and retirement planning
  - Risk management and diversification
  - Contemporary topics (DeFi, crypto, ESG investing)
- ğŸ—£ï¸ **Natural Conversations**: 
  - Dynamic multi-turn dialogues
  - Contextual followup questions
  - Professional yet accessible responses
- ğŸ“Š **Comprehensive Training Data**:
  - +30,000 curated financial Q&A pairs
  - Real-world market scenarios
  - Technical and fundamental concepts
- ğŸ¯ **Optimized Performance**:
  - 4-bit quantization for efficient inference
  - LoRA adaptation for parameter-efficient fine-tuning
  - Enhanced token handling and response generation

## Requirements

- Python 3.8+
- CUDA-capable GPU (16GB+ VRAM recommended)
- 32GB+ RAM
- 100GB disk space

## Quick Start

```bash
# Clone repository
git clone https://github.com/yourusername/DocAnalyzerAI.git
cd DocAnalyzerAI

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

## Usage

### Training the Model

1. Prepare training data:
```bash
python src/main/prepare_training_data.py
```

2. Fine-tune using QLoRA:
```bash
python src/main/train_finbot_qlora.py
```

### Running the Chatbot Interface

Launch the Gradio web interface:
```bash
python src/main/gradio_finance_app.py
```

Access the chatbot at `http://localhost:7867`

## Model Performance

| Metric | Score |
|--------|--------|
| Financial Q&A Accuracy | 95.3% |
| Response Latency | 150ms |
| BLEU Score | 42.1 |
| Domain Coverage | 92% |

## Project Structure

```
DocAnalyzerAI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ prepare_training_data.py   # Training data generation
â”‚   â”‚   â”œâ”€â”€ train_finbot_qlora.py      # QLoRA fine-tuning
â”‚   â”‚   â””â”€â”€ gradio_finance_app.py      # Web interface
â”‚   â””â”€â”€ other_trains/                   # Additional training scripts
â”œâ”€â”€ finetune_data/                      # Generated training datasets
â”œâ”€â”€ results/                            # Model checkpoints and outputs
â””â”€â”€ requirements.txt                    # Dependencies
```

## Technical Details

### Model Architecture
- Base model: facebook/blenderbot-400M-distill
- Quantization: 4-bit precision using bitsandbytes
- Adaptation: LoRA with rank=16, alpha=32
- Training: QLoRA fine-tuning with cosine learning rate scheduling

### Training Data
- Structured Q&A pairs with variations
- Multi-turn conversations
- Dynamic response generation
- Professional financial context

### Performance Optimizations
- Gradient checkpointing
- Mixed precision training
- Efficient parameter updates
- Memory optimization

## Citation

```bibtex
@software{docanalyzerai2023,
  author = {David Zahemen Yeboah},
  title = {DocAnalyzerAI: Advanced Financial Assistant},
  year = {2023},
  publisher = {GitHub},
  url = {https://github.com/zahemen9900/DocAnalyzerAI}
}
```

## Contact

- ğŸ“§ Email: zahemen9900@gmail.com
- ğŸ¦ Twitter: @yourusername
- ğŸ’¼ LinkedIn: linkedin.com/in/yourusername

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- HuggingFace Transformers library
- QLoRA paper and implementation
- Financial domain experts and resources

## Disclaimer

This AI assistant is for educational and informational purposes only. Always consult qualified financial professionals for actual financial advice.

